{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: YouTube Data Collection\n",
    "\n",
    "## Objective\n",
    "Collect YouTube video data from two independent sources:\n",
    "1. Web Scraping using Selenium\n",
    "2. YouTube Data API v3\n",
    "\n",
    "Target: 3000+ videos from each source for model training and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add source directory to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src import scraping, youtube_api\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"YOUTUBE DATA COLLECTION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Web Scraping\n",
    "\n",
    "Collect video metadata using Selenium WebDriver.\n",
    "This method extracts publicly visible data from YouTube search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPART 1: WEB SCRAPING\")\n",
    "print(\"=\"*80)\n",
    "print(\"Note: This may take 30-60 minutes for 3000+ videos.\")\n",
    "print(\"Set headless=True to run without browser window.\\n\")\n",
    "\n",
    "# Collect diverse dataset using automated function\n",
    "scraped_data = scraping.collect_diverse_dataset(\n",
    "    target_count=3000,\n",
    "    output_file=\"../data/raw/scraped_videos.csv\",\n",
    "    headless=True\n",
    ")\n",
    "\n",
    "print(f\"\\nScraped Data Collection Complete: {len(scraped_data)} videos\")\n",
    "print(f\"Saved to: data/raw/scraped_videos.csv\")\n",
    "\n",
    "# Display sample\n",
    "if scraped_data:\n",
    "    df_scraped = pd.read_csv(\"../data/raw/scraped_videos.csv\")\n",
    "    print(f\"\\nSample of scraped data:\")\n",
    "    print(df_scraped.head(3))\n",
    "    print(f\"\\nColumns: {list(df_scraped.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: YouTube Data API\n",
    "\n",
    "Collect structured video metadata using official YouTube Data API v3.\n",
    "Requires API key from Google Cloud Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPART 2: YOUTUBE DATA API\")\n",
    "print(\"=\"*80)\n",
    "print(\"Note: Requires YouTube API key in .env file\")\n",
    "print(\"Get API key from: https://console.cloud.google.com/\\n\")\n",
    "\n",
    "# Check if API key exists\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"WARNING: YOUTUBE_API_KEY not found!\")\n",
    "    print(\"Please create a .env file with: YOUTUBE_API_KEY=your_api_key_here\")\n",
    "    print(\"Skipping API collection...\")\n",
    "    api_data = []\n",
    "else:\n",
    "    # Collect API data\n",
    "    api_data = youtube_api.collect_diverse_dataset(\n",
    "        target_count=3000,\n",
    "        output_file=\"../data/raw/api_videos.csv\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAPI Data Collection Complete: {len(api_data)} videos\")\n",
    "    print(f\"Saved to: data/raw/api_videos.csv\")\n",
    "    \n",
    "    # Display sample\n",
    "    if api_data:\n",
    "        df_api = pd.read_csv(\"../data/raw/api_videos.csv\")\n",
    "        print(f\"\\nSample of API data:\")\n",
    "        print(df_api.head(3))\n",
    "        print(f\"\\nColumns: {list(df_api.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA COLLECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nScraped Videos: {len(scraped_data):,}\")\n",
    "print(f\"API Videos: {len(api_data):,}\")\n",
    "print(f\"Total Videos: {len(scraped_data) + len(api_data):,}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Next Steps:\")\n",
    "print(\"  1. Run notebook 02_preprocessing.ipynb\")\n",
    "print(\"  2. Run notebooks 03 & 04 to train models\")\n",
    "print(\"  3. Run notebook 05 for evaluation\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
