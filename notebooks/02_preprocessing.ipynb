{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Data Preprocessing and Feature Engineering\n",
    "\n",
    "## Objective\n",
    "Clean and prepare the collected data for machine learning:\n",
    "1. Parse text fields to numeric/datetime values\n",
    "2. Handle missing values\n",
    "3. Engineer features\n",
    "4. Save processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add source directory to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src import preprocess\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocess Scraped Data\n",
    "\n",
    "Parse and clean data collected via web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPART 1: PREPROCESSING SCRAPED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_scraped = preprocess.preprocess_scraped_data(\n",
    "    filename=\"../data/raw/scraped_videos.csv\",\n",
    "    output=\"../data/processed/scraped_processed.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nScraped Data Sample (after preprocessing):\")\n",
    "print(df_scraped.head(3))\n",
    "\n",
    "print(\"\\nScraped Data Info:\")\n",
    "print(f\"  Shape: {df_scraped.shape}\")\n",
    "print(f\"  Columns: {list(df_scraped.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preprocess API Data\n",
    "\n",
    "Parse and clean data collected via YouTube Data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPART 2: PREPROCESSING API DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_api = preprocess.preprocess_api_data(\n",
    "    filename=\"../data/raw/api_videos.csv\",\n",
    "    output=\"../data/processed/api_processed.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nAPI Data Sample (after preprocessing):\")\n",
    "print(df_api.head(3))\n",
    "\n",
    "print(\"\\nAPI Data Info:\")\n",
    "print(f\"  Shape: {df_api.shape}\")\n",
    "print(f\"  Columns: {list(df_api.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nScraped Data Features:\")\n",
    "for col in df_scraped.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nAPI Data Features:\")\n",
    "for col in df_api.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Scraped: {len(df_scraped):,} videos processed\")\n",
    "print(f\"API: {len(df_api):,} videos processed\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  - data/processed/scraped_processed.csv\")\n",
    "print(\"  - data/processed/api_processed.csv\")\n",
    "print(\"\\nNext: Run notebook 03 & 04 to train models\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
